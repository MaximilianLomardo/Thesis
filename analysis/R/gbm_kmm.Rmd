---
title: "GBM - Multiple Kernel KMeans"
author: "Maximilian Lombardo"
date: "January 14, 2018"
output: html_document
params:
  ge.txt: "~/Documents/gitRepos/master/data/SNF/GBM/GLIO_Gene_Expression.txt"
  mirna.txt: "~/Documents/gitRepos/master/data/SNF/GBM/GLIO_Mirna_Expression.txt"
  meth.txt: "~/Documents/gitRepos/master/data/SNF/GBM/GLIO_Methy_Expression.txt"
  survival.txt: "~/Documents/gitRepos/master/data/SNF/GBM/GLIO_Methy_Expression.txt"
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(kernlab)
library(classInt)
library(SNFtool)
library(cluster)
```

```{r}
file.path = "~/Documents/gitRepos/master/analysis/R/gbm_kmm_fxns.R"
source(file.path)
```

```{r}
file.locations <- chooseDataType("BREAST")
```


```{r}

#Data from the network Similarity Fusion Paper

#Before applying our SNF, we performed three steps of preprocessing: outlier removal, missing-data imputation and normalization. If a patient had more than 20% missing data in a certain data type, we did not consider this patient. Similarly, if a certain biological feature (for example, mRNA expression) had more than 20% of missing values across patients, we filtered out this feature. Also, for missing data, we used K nearest neighbor (KNN) imputation21, where the number of neighbors is the same with K value used in our method (see below); therefore we do not have any free parameters. Last, before constructing the patient network, we performed the following normalization: >>>>Z - score normalization



#where f is any biological feature,  is the corresponding feature after normalization, E(f) and Var(f) represent the empirical mean and variance of f, respectively.

#load in the data
ge <- read.table(params$ge.txt)
mirna <- read.table(params$mirna.txt)
meth <- read.table(params$meth.txt)
survival <- read.table(params$survival.txt, header = TRUE)

#load in the data

data.names <- c("gene","mirna", "meth", "survival")
data.name.indices <- lapply(data.names, FUN = grepl, file.locations, ignore.case = TRUE)
data.types <- unlist(lapply(data.name.indices, FUN = function(index){data.names[index]}))
grep("gene",  file.locations, ignore.case = TRUE)


data.views <- lapply(file.locations, FUN = function(locale){
  if(grepl("survival", locale, ignore.case = TRUE)){read.table(locale, header = TRUE)}else{read.table(locale)}})


names(data.views) <- data.types

targets <- data.views$survival

data.views <- data.views[setdiff(data.types, "survival")]
```

```{r}
#Partition the survival data into 3 classes
```


```{r}
#create gaussian kernels for each of the data types using the kernlab package

#These are just the indvidual kernel functions that compute the (modified) dot-product between two vectors...need to write a wrapper function to compute the kernel matrix for multiple samples...Need to tune sigma better
#rbf.ge <- rbfdot(sigma = sqrt(nrow(ge)))
#rbf.mirna <- rbfdot(sigma = sqrt(nrow(mirna)))
#rbf.meth <- rbfdot(sigma = sqrt(nrow(meth)))

#Using scaled variations of 1/nfeatures seems to work out well for sigma, in terms of having a diverse array of similarity values
rbf.ge <- rbfdot(sigma = 1/(4*nrow(ge)))
rbf.mirna <- rbfdot(sigma = 1/(nrow(mirna)))
rbf.meth <- rbfdot(sigma = 1/(2*nrow(meth)))


kernels <- list(rbf.ge, rbf.mirna, rbf.meth)


#calls to kernel construction function
ge.kern <- computeKernelMatrix(ge, rbf.ge)
mirna.kern <- computeKernelMatrix(mirna, rbf.mirna)
meth.kern <- computeKernelMatrix(meth, rbf.meth)

kernel.list <- lapply(c(1:length(data.views)), FUN = function(idx){computeKernelMatrix(data.views[idx], kernels[idx])})


all.kernels <- array(unlist(kernel.list), dim = c(nrow(kernel.list[1]), ncol(kernel.list[1]), length(kernel.list)))

```


```{r}
#Calculating the similarity matrix for target variables

#An attempt at Kernel-Target Alignment to optimize sigma parameter on RBF kernel. 
survival.similarity <- computeKernelMatrix1D(survival)

hist(survival.similarity)

#visualize similarites between patient survival lengths
image(survival.similarity[order(survival$Survival), order(survival$Survival)])



```

```{r}
#kernel Target alignment function

data.views.kern.kl <- lapply(data.views, kernelTargetAlignment, survival.similarity)

```

```{r}
### Generate kernel matrices using kernlab's internal functions... maybe dont use, seems to take a lot of memory?
'''
generate.rbf.kernels <- function(){
  kernels <- list()
  sigmas <- c(1:2 %o% 10^-(4:5))
  #sigmas <- c(1:9 %o% 10^-(4:5))
  for(i in 1:length(sigmas)){
    #print(i)
    kernels[[i]] <- rbfdot(sigma = sigmas[i])
  }
  return(kernels)
}

make.kernels.kernlab <- function(kernels, data){
  kernel.matrices <- list()
  for(i in 1:length(kernels)){
    print(i)
    kernel.matrices[[i]] <- kernelMatrix(kernels[[i]], as.matrix(data))
  }
  return(kernel.matrices)
}

kernels <- generate.rbf.kernels()
'''

```


```{r}
library(Rmosek)

mkkmeans_train <- function(Km, parameters) {
  state <- list()
  state$time <- system.time({
    P <- dim(Km)[3]
    theta <- rep(1 / P, P)
    K_theta <- matrix(0, nrow(Km), ncol(Km))
    for (m in 1:P) {
      K_theta <- K_theta + theta[m]^2 * Km[,,m]  
    }

    objective <- rep(0, parameters$iteration_count)
    for (iter in 1:parameters$iteration_count) {
      #print(sprintf("running iteration %d...", iter))
      H <- eigen(K_theta, symmetric = TRUE)$vectors[, 1:parameters$cluster_count]

      problem <- list()
      problem$sense <- "min"
      problem$c <- rep(0, P)
      problem$A <- Matrix(1, nrow = 1, ncol = P, sparse = TRUE)
      problem$bc <- rbind(blc = 1, buc = 1) 
      problem$bx <- rbind(blx = rep(0, P), bux = rep(1, P))
      problem$qobj <- list(i = 1:P, j = 1:P, v = sapply(1:P, function(m) {sum(diag(Km[,,m])) - sum(diag(t(H) %*% Km[,,m] %*% H))}))
      opts <- list()
      opts$verbose <- 0
      result <- mosek(problem, opts)
      theta <- result$sol$itr$xx
      K_theta <- matrix(0, nrow(Km), ncol(Km))
      for (m in 1:P) {
        K_theta <- K_theta + theta[m]^2 * Km[,,m]  
      }

      objective[iter] <- sum(diag(t(H) %*% K_theta %*% H)) - sum(diag(K_theta))
    }
    H_normalized <- H / matrix(sqrt(rowSums(H^2, 2)), nrow(H), parameters$cluster_count, byrow = FALSE)

    set.seed(NULL)
    state$clustering <- kmeans(H_normalized, centers = parameters$cluster_count, iter.max = 1000, nstart = 10)$cluster
    state$objective <- objective
    state$parameters <- parameters
    state$theta <- theta
  })
  return(state)
}
```

```{r}
mkkmeans_train_alternate <- function(Km, parameters) {
  require(Rmosek)
  state <- list()
  
    P <- dim(Km)[3]
    theta <- rep(1 / P, P)
    K_theta <- matrix(0, nrow(Km), ncol(Km))
    for (m in 1:P) {
      K_theta <- K_theta + theta[m]^2 * Km[,,m]  
    }

    objective <- rep(0, parameters$iteration_count)
    for (iter in 1:parameters$iteration_count) {
      #print(sprintf("running iteration %d...", iter))
      H <- eigen(K_theta, symmetric = TRUE)$vectors[, 1:parameters$cluster_count]

      problem <- list()
      problem$sense <- "min"
      problem$c <- rep(0, P)
      problem$A <- Matrix(1, nrow = 1, ncol = P, sparse = TRUE)
      problem$bc <- rbind(blc = 1, buc = 1) 
      problem$bx <- rbind(blx = rep(0, P), bux = rep(1, P))
      problem$qobj <- list(i = 1:P, j = 1:P, v = sapply(1:P, function(m) {sum(diag(Km[,,m])) - sum(diag(t(H) %*% Km[,,m] %*% H))}))
      opts <- list()
      opts$verbose <- 0
      result <- mosek(problem, opts)
      theta <- result$sol$itr$xx
      K_theta <- matrix(0, nrow(Km), ncol(Km))
      for (m in 1:P) {
        K_theta <- K_theta + theta[m]^2 * Km[,,m]  
      }

      objective[iter] <- sum(diag(t(H) %*% K_theta %*% H)) - sum(diag(K_theta))
    }
    H_normalized <- H / matrix(sqrt(rowSums(H^2, 2)), nrow(H), parameters$cluster_count, byrow = FALSE)

    set.seed(NULL)
    state$clustering <- kmeans(H_normalized, centers = parameters$cluster_count, iter.max = 1000, nstart = 10)$cluster
    state$objective <- objective
    state$parameters <- parameters
    state$theta <- theta
  
  return(state)
}
```



```{r}

assessClusterNumberAlternate <- function(all.kernels){
  
  states <- list()
  
  for(i in 2:10){
    #initalize the parameters of the algorithm
    parameters <- list()
  
    #set the number of clusters
    parameters$cluster_count <- i
  
    #set the number of iterations
    parameters$iteration_count <- 10
  
    #initialize the kernels
    K <- all.kernels #should be an N x N x P matrix containing similarity values between samples
  
    #perform training
    state <- mkkmeans_train_alternate(K, parameters)
    
    states[[i]] <- state
  }
  return(states)
}

assessClusterNumber <- function(all.kernels){
  
  states <- list()
  
  for(i in 2:10){
    #initalize the parameters of the algorithm
    parameters <- list()
  
    #set the number of clusters
    parameters$cluster_count <- i
  
    #set the number of iterations
    parameters$iteration_count <- 10
  
    #initialize the kernels
    K <- all.kernels #should be an N x N x P matrix containing similarity values between samples
  
    #perform training
    state <- mkkmeans_train(K, parameters)
    
    states[[i]] <- state
  }
  return(states)
}


states <- assessClusterNumber(all.kernels)


```

```{r}
# Combine kernels

combineKernels <- function(kernels, kernel.params){
  for(i in 1:length(kernel.params)){
    #print(i)
    kernels[, ,i] <- kernels[, ,i] * kernel.params[i]
  }
  return(apply(kernels, c(1,2), sum))
}

#combined.kernel <- combineKernels(all.kernels, state$theta)

combined.kernel <- combineKernels(all.kernels, states[[3]]$theta)

```

```{r}
#reorg <- order(state$clustering)
#reorg.combined.kernel <- combined.kernel[reorg, reorg]


displayClustersWithHeatmap(ge.kern, state$clustering)
displayClustersWithHeatmap(mirna.kern, state$clustering)
displayClustersWithHeatmap(meth.kern, state$clustering)
displayClustersWithHeatmap(combined.kernel, state$clustering)

```

```{r}
#Trying out the SNF tool



```

```{r}
###Use Nico Speicher's method of tuning the sigma parameter for the rbf kernel, also try making the kernel matrices based on PCA result of each data matrix...100 components each
library(FactoMineR)


#ge.comp <- PCA(X = ge, scale.unit = FALSE, ncp = 500)
#ge.comp <- t(ge.comp$var$coord)

#meth.comp <- PCA(X = meth, scale.unit = FALSE, ncp = 500)
#meth.comp <- t(meth.comp$var$coord)

#mirna.comp <- PCA(X = mirna, scale.unit = FALSE, ncp = 500)
#mirna.comp <- t(mirna.comp$var$coord)
############################################################################
rbf.ge <- rbfdot(sigma = 1/((2*(100^2))))
rbf.mirna <- rbfdot(sigma = 1/(2*(50^2)))
rbf.meth <- rbfdot(sigma = 1/(2*(100^2)))


#calls to kernel construction function
ge.kern <- computeKernelMatrix(ge, rbf.ge)
mirna.kern <- computeKernelMatrix(mirna, rbf.mirna)
meth.kern <- computeKernelMatrix(meth, rbf.meth)

all.kernels <- array(c(ge.kern, mirna.kern, meth.kern), dim = c(nrow(ge.kern), ncol(ge.kern), 3))


states <- assessClusterNumber(all.kernels)

combined.kernel <- combineKernels(all.kernels, states[[3]]$theta)

displayClustersWithHeatmap(ge.kern, states[[3]]$clustering)
displayClustersWithHeatmap(mirna.kern, states[[3]]$clustering)
displayClustersWithHeatmap(meth.kern, states[[3]]$clustering)
displayClustersWithHeatmap(combined.kernel, states[[3]]$clustering)

displayOrderedMatrix <- function(kernel, clustering){
  image(kernel[order(clustering), order(clustering)])
}


displayOrderedMatrix(ge.kern, states[[3]]$clustering)
displayOrderedMatrix(mirna.kern, states[[3]]$clustering)
displayOrderedMatrix(meth.kern, states[[3]]$clustering)
displayOrderedMatrix(combined.kernel, states[[3]]$clustering)


displayOrderedMatrix(ge.kern, spectralClustering(ge.kern, K = 3))

```

```{r}
####Asses cluster quality using silhouette scores

ge.dist <- as.matrix(dist(x = t(ge), method = "manhattan", diag = TRUE, upper = TRUE))
meth.dist <- as.matrix(dist(x = t(meth), method = "manhattan", diag = TRUE, upper = TRUE))
mirna.dist <- as.matrix(dist(x = t(mirna), method = "manhattan", diag = TRUE, upper = TRUE))

getSilhouetteScore <- function(clustering, distanceMatrix = ge.dist){
  silhouettes <- as.matrix(silhouette(clustering,dmatrix = distanceMatrix))
  avg.silhouette.score <- mean(silhouettes[,3])
  return(avg.silhouette.score)
}

plotAvgSilhouetteScores <- function(states, ge.dist, meth.dist, mirna.dist){
  ge.avg.silhouette.score <- unlist(lapply(2:length(states),
                                    FUN = function(i){getSilhouetteScore(states[[i]]$clustering,ge.dist)}))
  mirna.avg.silhouette.score <- unlist(lapply(2:length(states),
                                    FUN = function(i){getSilhouetteScore(states[[i]]$clustering,mirna.dist)}))
  meth.avg.silhouette.score <- unlist(lapply(2:length(states),
                                    FUN = function(i){getSilhouetteScore(states[[i]]$clustering,meth.dist)}))
  
  plot( c(2:10), ge.avg.silhouette.score, main = "Gene Expression",
        xlab = "Number of Clusters", ylab = "Average Silhouette Score")
  plot( c(2:10), mirna.avg.silhouette.score, main = "MiRNA",
        xlab = "Number of Clusters", ylab = "Average Silhouette Score")
  plot( c(2:10), meth.avg.silhouette.score, main = "Methylation",
        xlab = "Number of Clusters", ylab = "Average Silhouette Score")
}


plotAvgSilhouetteScores(states, ge.dist, meth.dist, mirna.dist)




```
```{r}
##Use above silhouette plots to decide on best cluster number

combined.kernel <- combineKernels(all.kernels, states[[2]]$theta)


displayOrderedMatrix <- function(kernel, clustering){
  image(kernel[order(clustering), order(clustering)])
}


displayOrderedMatrix(ge.kern, states[[2]]$clustering)
displayOrderedMatrix(mirna.kern, states[[2]]$clustering)
displayOrderedMatrix(meth.kern, states[[2]]$clustering)
displayOrderedMatrix(combined.kernel, states[[2]]$clustering)


displayClustersWithHeatmap(ge.kern, states[[2]]$clustering)
displayClustersWithHeatmap(mirna.kern, states[[2]]$clustering)
displayClustersWithHeatmap(meth.kern, states[[2]]$clustering)
displayClustersWithHeatmap(combined.kernel, states[[2]]$clustering)

#displayOrderedMatrix(ge.kern, spectralClustering(ge.kern, K = 5))

```


```{r}
###SIMLR
normalit<-function(m){
    return (m - min(m))/(max(m)-min(m))
}


c <- 4
ge.SIMLR <- SIMLR(X = ge, c)
ge.kern <- 1 - ge.SIMLR$S


meth.SIMLR <- SIMLR(X = meth, c)
meth.kern <- 1 - meth.SIMLR$S

mirna.SIMLR <- SIMLR(X = mirna, c)
mirna.kern <- 1 - mirna.SIMLR$S


#displayClustersWithHeatmap(test$S, test$y$cluster)

####MKL

all.kernels <- array(c(ge.kern, mirna.kern, meth.kern), dim = c(nrow(ge.kern), ncol(ge.kern), 3))


states <- assessClusterNumberAlternate(all.kernels)



##Sil
ge.dist <- as.matrix(dist(x = t(ge), method = "manhattan", diag = TRUE, upper = TRUE))
meth.dist <- as.matrix(dist(x = t(meth), method = "manhattan", diag = TRUE, upper = TRUE))
mirna.dist <- as.matrix(dist(x = t(mirna), method = "manhattan", diag = TRUE, upper = TRUE))

plotAvgSilhouetteScores(states, ge.dist, meth.dist, mirna.dist)

##Plot matrix

displayClustersWithHeatmap(ge.kern, states[[2]]$clustering)
displayClustersWithHeatmap(mirna.kern, states[[2]]$clustering)
displayClustersWithHeatmap(meth.kern, states[[2]]$clustering)
displayClustersWithHeatmap(combined.kernel, states[[2]]$clustering)

```

