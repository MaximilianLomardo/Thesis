---
title: "makePlots"
author: "Maximilian Lombardo"
date: "August 14, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Making figures using simulated data
#Make sure to have local version of SNFTool installed
#Load utility functions
#util.fxns <- "~/Documents/uva/master/the/utils/simMVData.R" 
util.fxns <- "~/Documents/gitRepos/master/utils/simMVData.R"
source(util.fxns)


#snf.fxns <- "~/Documents/uva/master/the/utils/snf_fxns.R"
snf.fxns <- "~/Documents/gitRepos/master/utils/snf_fxns.R"
source(snf.fxns)

#plotting.fxns <- "~/Documents/uva/master/the/utils/plotting_fxns.R"
plotting.fxns <- "~/Documents/gitRepos/master/utils/plotting_fxns.R"
source(plotting.fxns)

###Clean up this particular set of functions, redundant
#exp.plot.fxns <- "~/Documents/gitRepos/master/utils/simulatedExploratoryPlots.R"
#source(exp.plot.fxns)
```

```{r}
#Load Simulated Data from Similarity Network Fusion
library(SNFtool)



#Data and Labels for simulated scenario B
noise.sim <- simulateNoisyData(gaussian.noise = 3, gamma.noise = 4)

#Data and labels for simulated Scenario C
#misclass.sim <- simulateMisclassificationData(num = 1000, rad = 2.2)
perturb.sim <- simulatePerturbationData(num = 1000, pct.switch = 0.2)
```


```{r}
#Chapter 4 Figures
#Figure 1 Individual Simulated Data Scatter Views

#Add more types of noise to this figure and get rid of second portion?
#Scenario B Gaussian and Gamma Noise added to ground truth
plotSimDataScatter(dat = noise.sim$ground.truth[,c("V1", "V2")],
                   lab = noise.sim$ground.truth[,c("label")],
                   main.title =  "Noisy Simulated Data Ground Truth")
plotSimDataScatter(dat = noise.sim$gaussian.noise[,c("V1", "V2")],
                   lab = noise.sim$gaussian.noise[,c("label")],
                   main.title =  "Noisy Simulated Data Gaussian Noise")
plotSimDataScatter(dat = noise.sim$gamma.noise[,c("V1", "V2")],
                   lab = noise.sim$gamma.noise[,c("label")],
                   main.title =  "Noisy Simulated Data Gamma Noise")

# Scenario C Misclassification on the Boundaries of Groups
plotSimDataScatter(dat = perturb.sim$ground.truth[,c("V1", "V2")],
                   lab = perturb.sim$ground.truth[,c("label")],
                   main.title =  "Perturbation Simulation Ground Truth")
plotSimDataScatter(dat = perturb.sim$perturbation.1[,c("V1", "V2")],
                   lab = perturb.sim$perturbation.1[,c("label")],
                   main.title =  "Perturbation Simulation Scenario 1")
plotSimDataScatter(dat = perturb.sim$perturbation.2[,c("V1", "V2")],
                   lab = perturb.sim$perturbation.2[,c("label")],
                   main.title =  "Perturbation Simulation Scenario 2")

```



```{r}
#Chapter 4 Figures
#Figure 2 Similarity Network Fusion Heat Comparison
#Scenario A - inverted labels

#Scenario B - Noisy views
snf.b <- runSNFPipeline(Data1 = noise.sim$gaussian.noise,
                        Data2 = noise.sim$gamma.noise,
                        truelabel = noise.sim$true.label,
                        alpha = 1, down.pct = 0.2)
b.nmi <- plotSNFHeatComparison(all.data = snf.b$affinity.matrices,
                               truelabel = noise.sim$true.label,
                               down.pct = 0.2)
#Scenario C - perturbation
snf.c <- runSNFPipeline(Data1 = perturb.sim$perturbation.1,
                        Data2 = perturb.sim$perturbation.2,
                        truelabel = perturb.sim$true.label,
                        alpha = 1, down.pct = 0.2, K = 20)
c.nmi <- plotSNFHeatComparison(all.data = snf.c$affinity.matrices,
                               truelabel = perturb.sim$true.label,
                               down.pct = 0.2)

```

```{r}
#Chapter 4 Figures -- normalized mutual information histograms -- should I add multiple kernel learning here?

NMI.values <- c(unlist(snf.b$nmi.values), unlist(snf.c$nmi.values))

Simulated.Data <- factor(c(rep("Noise Simulation", 3), rep("Boundary Misclassification", 3)),
                         levels = c("Noise Simulation", "Boundary Misclassification"))

Views <- factor(rep(c("View 1", "View 2", "Fused"), 2), levels = c("View 1", "View 2", "Fused"))
#levels(conditions) <- c("View 1", "View 2", "Fused")

nmi.data <- data.frame(Simulated.Data, Views, NMI.values)

ggplot(nmi.data, aes(fill = Views, y = NMI.values, x = Simulated.Data)) +
  geom_bar(aes(fill = Views), stat = "identity", position = "dodge")

```


```{r}
#Chapter 4 - figure 3 multiple kernel k means
#K means multiple kernel learning as implemented by Mehmet Gonen
mkkm.fxns <- "~/Documents/uva/master/the/utils/mkkm_fxns_sim.R"


mkkm.a <- runMKKMPipeline(Data1 = noise.sim$gaussian.noise,
                          Data2 = noise.sim$gamma.noise,
                          truelabel = noise.sim$true.label)

mmkm.a.nmi <- plotSNFHeatComparison(all.data = mkkm.a$kernel.matrices,
                                    truelabel = noise.sim$true.label,
                                    down.pct = 0.2)

mkkm.b <- runMKKMPipeline(Data1 = perturb.sim$perturbation.1,
                          Data2 = perturb.sim$perturbation.2,
                          truelabel = perturb.sim$true.label,
                          scale.factor = 1/32)

mmkm.b.nmi <- plotSNFHeatComparison(all.data = mkkm.b$kernel.matrices,
                                    truelabel = noise.sim$true.label,
                                    down.pct = 0.2)


```

```{r}
#NMI values for the multiple kernel k means experiment

#Chapter 4 Figures -- normalized mutual information histograms -- should I add multiple kernel learning here?

NMI.values <- c(unlist(mkkm.a$nmi.values), unlist(mkkm.b$nmi.values))

Simulated.Data <- factor(c(rep("Noise Simulation", 3), rep("Boundary Misclassification", 3)),
                         levels = c("Noise Simulation", "Boundary Misclassification"))

Views <- factor(rep(c("View 1", "View 2", "Fused"), 2), levels = c("View 1", "View 2", "Fused"))
#levels(conditions) <- c("View 1", "View 2", "Fused")

nmi.data <- data.frame(Simulated.Data, Views, NMI.values)

ggplot(nmi.data, aes(fill = Views, y = NMI.values, x = Simulated.Data)) +
  geom_bar(aes(fill = Views), stat = "identity", position = "dodge")

```


```{r}
#Run SNF pipeline on GBM data (also with breast, kidney, liver...) from paper

snf.gbm <- processRealData(disease = "GBM")
#Manual parameters
C <-5
snf.gbm <- runSNFPipelineRealData(disease = "GBM", K = 10, C = C, num.pcs = 15, alpha = 0.3)

#Make some silhouette plots - Single Data View predictions against single data view distances package these silhouette plots up!
plot(snf.gbm$silhouette.values$single.view$ge,
     col = rainbow(C, s = 0.8),
     cex = 0.8,
     main = "Silhouette plot: Gene Expression View",
     nmax.lab = 60, max.strlen = 5,
     do.n.k = FALSE, do.clus.stat = TRUE)
plot(snf.gbm$silhouette.values$single.view$meth,
     col = rainbow(C, s = 0.8),
     cex = 0.8,
     main = "Silhouette plot: Methylation View",
     nmax.lab = 60, max.strlen = 5,
     do.n.k = FALSE, do.clus.stat = TRUE)
plot(snf.gbm$silhouette.values$single.view$mirna,
     col = rainbow(C, s = 0.8),
     cex = 0.8,
     main = "Silhouette plot: miRNA View",
     nmax.lab = 60, max.strlen = 5,
     do.n.k = FALSE, do.clus.stat = TRUE)

#More silhouette Plots - Fused Data View predictions against single data view distances --- 
plot(snf.gbm$silhouette.values$multi.view$ge,
     col = rainbow(C, s = 0.8),
     cex = 0.8,
     main = "Silhouette plot: Gene Expression View",
     nmax.lab = 60, max.strlen = 5,
     do.n.k = FALSE, do.clus.stat = TRUE)

plot(snf.gbm$silhouette.values$multi.view$meth,
     col = rainbow(C, s = 0.8),
     cex = 0.8,
     main = "Silhouette plot: Methylation View",
     nmax.lab = 60, max.strlen = 5,
     do.n.k = FALSE, do.clus.stat = TRUE)

plot(snf.gbm$silhouette.values$multi.view$mirna,
     col = rainbow(C, s = 0.8),
     cex = 0.8,
     main = "Silhouette plot: mirna View",
     nmax.lab = 60, max.strlen = 5,
     do.n.k = FALSE, do.clus.stat = TRUE)

## S3 method for class 'silhouette'
#plot(x, nmax.lab = 40, max.strlen = 5,
#     main = NULL, sub = NULL, xlab = expression("Silhouette width "* s[i]),
#     col = "gray",  do.col.sort = length(col) > 1, border = 0,
#     cex.names = par("cex.axis"), do.n.k = TRUE, do.clus.stat = TRUE, ...)



#Plot affinity matrices 


plotSNFHeatComparison2(all.data = snf.gbm$affinity.matrices,
                      true.labels = snf.gbm$identity,
                      down.pct = 1)
######################################################################################################
#Do the same for MKKM pipeline @TODO

```


```{r}
#Take the predictions that ar made from the SNF pipeline and construct survival curves from the fused predictions

#Plotting the survival curves for all GBM patients, grouped by predicitions made from the Similarity Network Fusion approach vs groupings for single dataviews??
#Survival curves of individual view predictions and fused predictions
plotSurvivalCurves(disease = "GBM",
                   group.prediction = snf.gbm$identity$ge)
plotSurvivalCurves(disease = "GBM",
                   group.prediction = snf.gbm$identity$meth)
plotSurvivalCurves(disease = "GBM",
                   group.prediction = snf.gbm$identity$mirna)
plotSurvivalCurves(disease = "GBM",
                   group.prediction = snf.gbm$identity$W_fused)

#Plot the cluster layout using a pca based or tsne based coordinate system...
#Quality of other data views?

plotClustersDRSpace(fused.view = snf.gbm$affinity.matrices$W_fused,
                    group.prediction = snf.gbm$affinity.matrices$W_fused,
                    reduction.use = "pca", main.title = "PCA reduction of fused Matrix")

#Discriminative features using the Similarity Network Fusion cluster assignments

disc.features <- discriminativeFeatureSelection(data.views, snf.gbm$identity$W_fused)

plotFeatureHeatMap(data.view = , features = names(disc.features$ge[1:100]))#Might need a better way to choose features
#Plotting the survival curves for all GBM patients, grouped by predicitions made from the Multiple Kernel K-Means method

#Plot dimensionality reduction of groupings/fused kernels found by multiple kernel K means...






```
